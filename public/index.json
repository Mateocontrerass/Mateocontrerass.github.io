[{"content":"\rLinks GitHub Description For this project I built a image classifier using the FastAI library to identify over 100 species of flowers. The dataset used for this project can be found Here and it\u0026rsquo;s part of an Oxford\u0026rsquo;s University repository.\nThis is my first real Deep Learning project and I have been following the fastAI methodology of building and then understanding each part and technique.\nImport libraries # It\u0026#39;s always good to have the latest version of fastAI library. !pip install -Uqq fastai !pip install timm import json import timm import pandas as pd import torchvision import torch import fastai import requests from fastai.vision import * from torchvision.transforms import RandomHorizontalFlip, RandomVerticalFlip, ColorJitter, RandomRotation, RandomResizedCrop, RandomResizedCrop, Compose, ToTensor, Normalize from fastai.vision.all import * from fastai import * from pathlib import Path from fastai.data.external import untar_data, URLs Note: It is not a good practice to import libraries using *. However, in this iteration I am aiming to a more interactive approach.\nLoad data I am going to use a fastAI method to download the data from a subdirectory saved in the library using a URL. It has a folder that contains the pictures and three different text files (train, test and valid).\nruta = untar_data(URLs.FLOWERS) Note: There is no need to download the dataset previously because the former line just did that.\ntrain_txt = pd.read_csv(str(ruta)+\u0026#39;/train.txt\u0026#39;, sep =\u0026#39; \u0026#39;, names=[\u0026#39;nombre\u0026#39;, \u0026#39;index\u0026#39;]) val_txt = pd.read_csv(str(ruta)+\u0026#39;/valid.txt\u0026#39;, sep =\u0026#39; \u0026#39;, names=[\u0026#39;nombre\u0026#39;, \u0026#39;index\u0026#39;]) The data contains details about the flowers, including the name of the .png files and a number to indicate the category . However, we need to translate these numbers into names, so we\u0026rsquo;ll be downloading a text file that contains this information, and with the help of a dictionary, we\u0026rsquo;ll rename the numbers to names.\nURL = \u0026#39;https://gist.githubusercontent.com/JosephKJ/94c7728ed1a8e0cd87fe6a029769cde1/raw/403325f5110cb0f3099734c5edb9f457539c77e9/Oxford-102_Flower_dataset_labels.txt\u0026#39; categorias = pd.read_csv(URL, sep=\u0026#39;\\t\u0026#39;, header=None, names=[\u0026#39;Name\u0026#39;, \u0026#39;label\u0026#39;]) categorias[\u0026#39;label\u0026#39;] = categorias.index categorias[\u0026#39;Name\u0026#39;] = categorias[\u0026#39;Name\u0026#39;].str.replace(\u0026#34;\u0026#39;\u0026#34;, \u0026#34;\u0026#34;) categorias = categorias.to_dict()[\u0026#39;Name\u0026#39;] train_txt[\u0026#34;label\u0026#34;] = train_txt[\u0026#39;index\u0026#39;].map(categorias) val_txt[\u0026#34;label\u0026#34;] = val_txt[\u0026#39;index\u0026#39;].map(categorias) # Validation mark. train_txt[\u0026#39;is_valid\u0026#39;] =False val_txt[\u0026#39;is_valid\u0026#39;]=True # We concatenate the train and validation datasets. df = pd.concat([train_txt,val_txt]) df.nombre = df.nombre.apply(lambda x: f\u0026#39;{ruta}/{x}\u0026#39;) Feature engineering A common problem in machine learning is lacking data, specially using images. That\u0026rsquo;s why fastAI has a couple methods for Data Augmentation such as RandomResizedCrop and aug_transforms, both of which I will be using in this model.\n# Se crea el transformador de las imagenes para definir el tamaño de las imagenes que utilizamos objeto_transf = [RandomResizedCrop(192,min_scale=0.75, ratio=(1.,1.))] # Se crea el batch_transf para hacerle los siguientes pasos a las imagenes: # 1. Hacer data augmentation con un tamaño de 192 para aumentar la cantidad de ejemplos en el set # 2. se normalizan las imagenes para mejorar el rendimiento del modelo segun los stats de imagenet. batch_transf = [*aug_transforms(mult=2, size=192),Normalize.from_stats(*imagenet_stats)] Once we have all the data set up, we can create the DataBlock.\ndblock = DataBlock( blocks=(ImageBlock,CategoryBlock), get_x = ColReader(\u0026#39;nombre\u0026#39;), get_y = ColReader(\u0026#39;label\u0026#39;), item_tfms=objeto_transf, batch_tfms=batch_transf, splitter=ColSplitter(\u0026#39;is_valid\u0026#39;) ) flores = dblock.dataloaders(df) Training the model I am going to use a model that already knows how to do something well and train it to make something even better for our needs. This is called transfer learning and it allows us to train models faster.\nThe pretrained model I am going to use is called convnext_tiny_in22k (previously i tried a resnet50 variation but i found out that the model I am currently using has a better performance).\nmodel = timm.create_model(\u0026#39;convnext_tiny_in22k\u0026#39;, pretrained=True, num_classes=flores.c) learner_2 = Learner(flores, model, metrics= error_rate) learner_2.fine_tune(4) Saving the model The next line will download the model as a .pkl file which can be used to deploy the model.\nlearner_2.export() Model deployment To deploy the model I am going to use Hugging Face Spaces and Gradio using the following script. It will require to upload the .pkl file and an optional example file.\nfrom fastai.vision.all import * import gradio as gr import timm learner = load_learner(\u0026#34;./export.pkl\u0026#34;) categorias = learner.dls.vocab def clasificar_imagen(img): prediccion, indice, probabilidades = learner.predict(img) return dict(zip(categorias,map(float,probabilidades))) imagen = gr.inputs.Image(shape=(500,500)) etiqueta = gr.outputs.Label() ejemplo = [\u0026#39;girasol.jpg\u0026#39;] interfaz = gr.Interface(fn=clasificar_imagen,inputs=imagen,outputs=etiqueta, examples=ejemplo) interfaz.launch(inline=False) Try it out Check the result and let me know how it goes! :) ","permalink":"https://mateocontreras.onrender.com/projects/flower_classif/","summary":"Program that identifies over a 100 different species of flowers.","title":"Flower Classification using fastAI"},{"content":"\rHey, I'm Mateo Contreras.\nI\u0026rsquo;m a B.A. in Economics from Universidad de los Andes currently working and studying Analytics and ML.\nI worked as a logistics Data Analyst for Davivienda and I\u0026rsquo;m currently a Credit Risk Analyst at Banco de Bogotá.\nA fun fact about me: I love hiking and exploring new places.\n","permalink":"https://mateocontreras.onrender.com/about/","summary":"Information about me.","title":"About Me"},{"content":"This website was created with the static site generator Hugo using the PaperMod theme and is hosted on Netlify.\nThis website uses Google Analytics, which uses cookies. Please see Google\u0026rsquo;s Privacy Policy, Technologies, and How Google Uses Cookies for more information.\nAdditionally, this website uses giscus for comments. giscus uses cookies: Please see giscus\u0026rsquo; Privacy Policy for more information.\nLastly, this site remembers your theme preference (light or dark) in a cookie.\nIt is possible that Hugo, PaperMod, and Netlify collect information in ways that I am not aware of. Apart from the information described here and data collection I am not aware of, no other information is collected, stored, or evaluated.\n","permalink":"https://mateocontreras.onrender.com/privacy/","summary":"Privacy policy.","title":"Privacy Policy"}]