<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Flower Classification using fastAI | Mateo Contreras</title><meta name=keywords content="Python,Image Processing,Flowers"><meta name=description content="Program that identifies over a 100 different species of flowers."><meta name=author content="Mateo Contreras"><link rel=canonical href=/projects/neuroruler/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.c704cda54ded0124774ec2a5451c66616347e220842181e3e361cdff0515dbf9.css integrity="sha256-xwTNpU3tASR3TsKlRRxmYWNH4iCEIYHj42HN/wUV2/k=" rel="preload stylesheet" as=style><link rel=icon href=favicon/favicon><link rel=icon type=image/png sizes=16x16 href=favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=favicon-32x32.png><link rel=apple-touch-icon href=apple-touch-icon.png><link rel=mask-icon href=safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous onload='renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}]})'></script><style>@media screen and (min-width:769px){.post-content input[type=checkbox]:checked~label>img{transform:scale(1.6);cursor:zoom-out;position:relative;z-index:999}.post-content img.zoomCheck{transition:transform .15s ease;z-index:999;cursor:zoom-in}}</style><meta property="og:title" content="Flower Classification using fastAI"><meta property="og:description" content="Program that identifies over a 100 different species of flowers."><meta property="og:type" content="article"><meta property="og:url" content="/projects/neuroruler/"><meta property="og:image" content="img/flor.png"><meta property="article:section" content="projects"><meta property="article:published_time" content="2023-09-01T18:08:42-04:00"><meta property="article:modified_time" content="2023-09-01T18:08:42-04:00"><meta property="og:site_name" content="Mateo Contreras"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="img/flor.png"><meta name=twitter:title content="Flower Classification using fastAI"><meta name=twitter:description content="Program that identifies over a 100 different species of flowers."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Projects","item":"/projects/"},{"@type":"ListItem","position":3,"name":"Flower Classification using fastAI","item":"/projects/neuroruler/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Flower Classification using fastAI","name":"Flower Classification using fastAI","description":"Program that identifies over a 100 different species of flowers.","keywords":["Python","Image Processing","Flowers"],"articleBody":"\rLinks GitHub Description For this project I built a image classifier using the FastAI library to identify over 100 species of flowers. The dataset used for this project can be found Here and it’s part of an Oxford’s University repository.\nThis is my first real Deep Learning project and I have been following the fastAI methodology of building and then understanding each part and technique.\nImport libraries # It's always good to have the latest version of fastAI library. !pip install -Uqq fastai !pip install timm import json import timm import pandas as pd import torchvision import torch import fastai import requests from fastai.vision import * from torchvision.transforms import RandomHorizontalFlip, RandomVerticalFlip, ColorJitter, RandomRotation, RandomResizedCrop, RandomResizedCrop, Compose, ToTensor, Normalize from fastai.vision.all import * from fastai import * from pathlib import Path from fastai.data.external import untar_data, URLs Note: It is not a good practice to import libraries using *. However, in this iteration I am aiming to a more interactive approach.\nLoad data I am going to use a fastAI method to download the data from a subdirectory saved in the library using a URL. It has a folder that contains the pictures and three different text files (train, test and valid).\nruta = untar_data(URLs.FLOWERS) Note: There is no need to download the dataset previously because the former line just did that.\ntrain_txt = pd.read_csv(str(ruta)+'/train.txt', sep =' ', names=['nombre', 'index']) val_txt = pd.read_csv(str(ruta)+'/valid.txt', sep =' ', names=['nombre', 'index']) The data contains details about the flowers, including the name of the .png files and a number to indicate the category . However, we need to translate these numbers into names, so we’ll be downloading a text file that contains this information, and with the help of a dictionary, we’ll rename the numbers to names.\nURL = 'https://gist.githubusercontent.com/JosephKJ/94c7728ed1a8e0cd87fe6a029769cde1/raw/403325f5110cb0f3099734c5edb9f457539c77e9/Oxford-102_Flower_dataset_labels.txt' categorias = pd.read_csv(URL, sep='\\t', header=None, names=['Name', 'label']) categorias['label'] = categorias.index categorias['Name'] = categorias['Name'].str.replace(\"'\", \"\") categorias = categorias.to_dict()['Name'] train_txt[\"label\"] = train_txt['index'].map(categorias) val_txt[\"label\"] = val_txt['index'].map(categorias) # Validation mark. train_txt['is_valid'] =False val_txt['is_valid']=True # We concatenate the train and validation datasets. df = pd.concat([train_txt,val_txt]) df.nombre = df.nombre.apply(lambda x: f'{ruta}/{x}') Feature engineering A common problem in machine learning is lacking data, specially using images. That’s why fastAI has a couple methods for Data Augmentation such as RandomResizedCrop and aug_transforms, both of which I will be using in this model.\n# Se crea el transformador de las imagenes para definir el tamaño de las imagenes que utilizamos objeto_transf = [RandomResizedCrop(192,min_scale=0.75, ratio=(1.,1.))] # Se crea el batch_transf para hacerle los siguientes pasos a las imagenes: # 1. Hacer data augmentation con un tamaño de 192 para aumentar la cantidad de ejemplos en el set # 2. se normalizan las imagenes para mejorar el rendimiento del modelo segun los stats de imagenet. batch_transf = [*aug_transforms(mult=2, size=192),Normalize.from_stats(*imagenet_stats)] Once we have all the data set up, we can create the DataBlock.\ndblock = DataBlock( blocks=(ImageBlock,CategoryBlock), get_x = ColReader('nombre'), get_y = ColReader('label'), item_tfms=objeto_transf, batch_tfms=batch_transf, splitter=ColSplitter('is_valid') ) flores = dblock.dataloaders(df) Training the model I am going to use a model that already knows how to do something well and train it to make something even better for our needs. This is called transfer learning and it allows us to train models faster.\nThe pretrained model I am going to use is called convnext_tiny_in22k (previously i tried a resnet50 variation but i found out that the model I am currently using has a better performance).\nmodel = timm.create_model('convnext_tiny_in22k', pretrained=True, num_classes=flores.c) learner_2 = Learner(flores, model, metrics= error_rate) learner_2.fine_tune(4) Saving the model The next line will download the model as a .pkl file which can be used to deploy the model.\nlearner_2.export() Model deployment To deploy the model I am going to use Hugging Face Spaces and Gradio using the following script. It will require to upload the .pkl file and an optional example file.\nfrom fastai.vision.all import * import gradio as gr import timm learner = load_learner(\"./export.pkl\") categorias = learner.dls.vocab def clasificar_imagen(img): prediccion, indice, probabilidades = learner.predict(img) return dict(zip(categorias,map(float,probabilidades))) imagen = gr.inputs.Image(shape=(500,500)) etiqueta = gr.outputs.Label() ejemplo = ['girasol.jpg'] interfaz = gr.Interface(fn=clasificar_imagen,inputs=imagen,outputs=etiqueta, examples=ejemplo) interfaz.launch(inline=False) Try it out Check the result and let me know how it goes! :) ","wordCount":"677","inLanguage":"en","image":"img/flor.png","datePublished":"2023-09-01T18:08:42-04:00","dateModified":"2023-09-01T18:08:42-04:00","author":{"@type":"Person","name":"Mateo Contreras"},"mainEntityOfPage":{"@type":"WebPage","@id":"/projects/neuroruler/"},"publisher":{"@type":"Organization","name":"Mateo Contreras","logo":{"@type":"ImageObject","url":"favicon/favicon"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href accesskey=h title="Mateo Contreras (Alt + H)"><img src=/lucky_block.png alt="Site icon in header" aria-label=logo height=50>Mateo Contreras</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><button id=menu-trigger aria-haspopup=menu aria-label="Menu Button"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"/><line x1="3" y1="6" x2="21" y2="6"/><line x1="3" y1="18" x2="21" y2="18"/></svg></button><ul class="menu hidden"><li><a href=/about/ title=About><span>About</span></a></li><li><a href=/projects/ title=Projects><span>Projects</span></a></li><li><a href=/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href>Home</a>&nbsp;»&nbsp;<a href=/projects/>Projects</a></div><h1 class=post-title>Flower Classification using fastAI</h1><div class=post-meta><span title='2023-09-01 18:08:42 -0400 -0400'>September 1, 2023</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;Mateo Contreras</div></header><div class="toc side left"><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#links>Links</a></li><li><a href=#description>Description</a></li><li><a href=#import-libraries>Import libraries</a></li><li><a href=#load-data>Load data</a></li><li><a href=#feature-engineering>Feature engineering</a></li><li><a href=#training-the-model>Training the model</a></li><li><a href=#saving-the-model>Saving the model</a></li><li><a href=#model-deployment>Model deployment</a></li><li><a href=#try-it-out>Try it out</a></li></ul></nav></div></details></div><div class=post-content><p><input type=checkbox id=zoomCheck-16c55 hidden>
<label for=zoomCheck-16c55><img class=zoomCheck loading=lazy decoding=async src=img/flor.gif alt="NeuroRuler demo"></label></p><h2 id=links>Links<a hidden class=anchor aria-hidden=true href=#links>#</a></h2><ul><li><a href=https://github.com/Mateocontrerass/fastAI-to-make-a-flower-classifier>GitHub</a></li></ul><h2 id=description>Description<a hidden class=anchor aria-hidden=true href=#description>#</a></h2><p>For this project I built a image classifier using the FastAI library to identify over 100 species of flowers. The dataset used for this project can be found <a href=https://www.robots.ox.ac.uk/~vgg/data/flowers/102/index.html>Here</a> and it&rsquo;s part of an Oxford&rsquo;s University repository.</p><p>This is my first real Deep Learning project and I have been following the fastAI methodology of building and then understanding each part and technique.</p><h2 id=import-libraries>Import libraries<a hidden class=anchor aria-hidden=true href=#import-libraries>#</a></h2><div class=highlight><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=line><span class=cl><span class=c1># It&#39;s always good to have the latest version of fastAI library.</span>
</span></span><span class=line><span class=cl><span class=err>!</span><span class=n>pip</span> <span class=n>install</span> <span class=o>-</span><span class=n>Uqq</span> <span class=n>fastai</span>
</span></span><span class=line><span class=cl><span class=err>!</span><span class=n>pip</span> <span class=n>install</span> <span class=n>timm</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>json</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>timm</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torchvision</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>fastai</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>requests</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>fastai.vision</span> <span class=kn>import</span> <span class=o>*</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torchvision.transforms</span> <span class=kn>import</span> <span class=n>RandomHorizontalFlip</span><span class=p>,</span> <span class=n>RandomVerticalFlip</span><span class=p>,</span> <span class=n>ColorJitter</span><span class=p>,</span> <span class=n>RandomRotation</span><span class=p>,</span> <span class=n>RandomResizedCrop</span><span class=p>,</span> <span class=n>RandomResizedCrop</span><span class=p>,</span> <span class=n>Compose</span><span class=p>,</span> <span class=n>ToTensor</span><span class=p>,</span> <span class=n>Normalize</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>fastai.vision.all</span> <span class=kn>import</span> <span class=o>*</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>fastai</span> <span class=kn>import</span> <span class=o>*</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pathlib</span> <span class=kn>import</span> <span class=n>Path</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>fastai.data.external</span> <span class=kn>import</span> <span class=n>untar_data</span><span class=p>,</span> <span class=n>URLs</span>
</span></span></code></pre></div><p><em>Note: It is not a good practice to import libraries using *. However, in this iteration I am aiming to a more interactive approach.</em></p><h2 id=load-data>Load data<a hidden class=anchor aria-hidden=true href=#load-data>#</a></h2><p>I am going to use a fastAI method to download the data from a subdirectory saved in the library using a URL. It has a folder that contains the pictures and three different text files (train, test and valid).</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=line><span class=cl><span class=n>ruta</span> <span class=o>=</span> <span class=n>untar_data</span><span class=p>(</span><span class=n>URLs</span><span class=o>.</span><span class=n>FLOWERS</span><span class=p>)</span>
</span></span></code></pre></div><p><em>Note: There is no need to download the dataset previously because the former line just did that.</em></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=line><span class=cl><span class=n>train_txt</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=nb>str</span><span class=p>(</span><span class=n>ruta</span><span class=p>)</span><span class=o>+</span><span class=s1>&#39;/train.txt&#39;</span><span class=p>,</span> <span class=n>sep</span> <span class=o>=</span><span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>names</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;nombre&#39;</span><span class=p>,</span> <span class=s1>&#39;index&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>val_txt</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=nb>str</span><span class=p>(</span><span class=n>ruta</span><span class=p>)</span><span class=o>+</span><span class=s1>&#39;/valid.txt&#39;</span><span class=p>,</span> <span class=n>sep</span> <span class=o>=</span><span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>names</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;nombre&#39;</span><span class=p>,</span> <span class=s1>&#39;index&#39;</span><span class=p>])</span>
</span></span></code></pre></div><p>The data contains details about the flowers, including the name of the .png files and a number to indicate the category . However, we need to translate these numbers into names, so we&rsquo;ll be downloading a text file that contains this information, and with the help of a dictionary, we&rsquo;ll rename the numbers to names.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=line><span class=cl><span class=n>URL</span> <span class=o>=</span> <span class=s1>&#39;https://gist.githubusercontent.com/JosephKJ/94c7728ed1a8e0cd87fe6a029769cde1/raw/403325f5110cb0f3099734c5edb9f457539c77e9/Oxford-102_Flower_dataset_labels.txt&#39;</span>
</span></span><span class=line><span class=cl><span class=n>categorias</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=n>URL</span><span class=p>,</span> <span class=n>sep</span><span class=o>=</span><span class=s1>&#39;</span><span class=se>\t</span><span class=s1>&#39;</span><span class=p>,</span> <span class=n>header</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>names</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;Name&#39;</span><span class=p>,</span> <span class=s1>&#39;label&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>categorias</span><span class=p>[</span><span class=s1>&#39;label&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>categorias</span><span class=o>.</span><span class=n>index</span>
</span></span><span class=line><span class=cl><span class=n>categorias</span><span class=p>[</span><span class=s1>&#39;Name&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>categorias</span><span class=p>[</span><span class=s1>&#39;Name&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>str</span><span class=o>.</span><span class=n>replace</span><span class=p>(</span><span class=s2>&#34;&#39;&#34;</span><span class=p>,</span> <span class=s2>&#34;&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>categorias</span> <span class=o>=</span> <span class=n>categorias</span><span class=o>.</span><span class=n>to_dict</span><span class=p>()[</span><span class=s1>&#39;Name&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>train_txt</span><span class=p>[</span><span class=s2>&#34;label&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>train_txt</span><span class=p>[</span><span class=s1>&#39;index&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>map</span><span class=p>(</span><span class=n>categorias</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>val_txt</span><span class=p>[</span><span class=s2>&#34;label&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>val_txt</span><span class=p>[</span><span class=s1>&#39;index&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>map</span><span class=p>(</span><span class=n>categorias</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Validation mark.</span>
</span></span><span class=line><span class=cl><span class=n>train_txt</span><span class=p>[</span><span class=s1>&#39;is_valid&#39;</span><span class=p>]</span> <span class=o>=</span><span class=kc>False</span>
</span></span><span class=line><span class=cl><span class=n>val_txt</span><span class=p>[</span><span class=s1>&#39;is_valid&#39;</span><span class=p>]</span><span class=o>=</span><span class=kc>True</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># We concatenate the train and validation datasets.</span>
</span></span><span class=line><span class=cl><span class=n>df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>concat</span><span class=p>([</span><span class=n>train_txt</span><span class=p>,</span><span class=n>val_txt</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>df</span><span class=o>.</span><span class=n>nombre</span> <span class=o>=</span> <span class=n>df</span><span class=o>.</span><span class=n>nombre</span><span class=o>.</span><span class=n>apply</span><span class=p>(</span><span class=k>lambda</span> <span class=n>x</span><span class=p>:</span> <span class=sa>f</span><span class=s1>&#39;</span><span class=si>{</span><span class=n>ruta</span><span class=si>}</span><span class=s1>/</span><span class=si>{</span><span class=n>x</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
</span></span></code></pre></div><h2 id=feature-engineering>Feature engineering<a hidden class=anchor aria-hidden=true href=#feature-engineering>#</a></h2><p>A common problem in machine learning is lacking data, specially using images. That&rsquo;s why fastAI has a couple methods for Data Augmentation such as RandomResizedCrop and aug_transforms, both of which I will be using in this model.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=line><span class=cl><span class=c1># Se crea el transformador de las imagenes para definir el tamaño de las imagenes que utilizamos</span>
</span></span><span class=line><span class=cl><span class=n>objeto_transf</span> <span class=o>=</span> <span class=p>[</span><span class=n>RandomResizedCrop</span><span class=p>(</span><span class=mi>192</span><span class=p>,</span><span class=n>min_scale</span><span class=o>=</span><span class=mf>0.75</span><span class=p>,</span> <span class=n>ratio</span><span class=o>=</span><span class=p>(</span><span class=mf>1.</span><span class=p>,</span><span class=mf>1.</span><span class=p>))]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Se crea el batch_transf para hacerle los siguientes pasos a las imagenes:</span>
</span></span><span class=line><span class=cl><span class=c1># 1. Hacer data augmentation con un tamaño de 192 para aumentar la cantidad de ejemplos en el set</span>
</span></span><span class=line><span class=cl><span class=c1># 2. se normalizan las imagenes para mejorar el rendimiento del modelo segun los stats de imagenet.</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>batch_transf</span> <span class=o>=</span> <span class=p>[</span><span class=o>*</span><span class=n>aug_transforms</span><span class=p>(</span><span class=n>mult</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=mi>192</span><span class=p>),</span><span class=n>Normalize</span><span class=o>.</span><span class=n>from_stats</span><span class=p>(</span><span class=o>*</span><span class=n>imagenet_stats</span><span class=p>)]</span>
</span></span></code></pre></div><p>Once we have all the data set up, we can create the DataBlock.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=line><span class=cl><span class=n>dblock</span> <span class=o>=</span> <span class=n>DataBlock</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>blocks</span><span class=o>=</span><span class=p>(</span><span class=n>ImageBlock</span><span class=p>,</span><span class=n>CategoryBlock</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>get_x</span> <span class=o>=</span> <span class=n>ColReader</span><span class=p>(</span><span class=s1>&#39;nombre&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>get_y</span> <span class=o>=</span> <span class=n>ColReader</span><span class=p>(</span><span class=s1>&#39;label&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>item_tfms</span><span class=o>=</span><span class=n>objeto_transf</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>batch_tfms</span><span class=o>=</span><span class=n>batch_transf</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>splitter</span><span class=o>=</span><span class=n>ColSplitter</span><span class=p>(</span><span class=s1>&#39;is_valid&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>flores</span> <span class=o>=</span> <span class=n>dblock</span><span class=o>.</span><span class=n>dataloaders</span><span class=p>(</span><span class=n>df</span><span class=p>)</span>
</span></span></code></pre></div><h2 id=training-the-model>Training the model<a hidden class=anchor aria-hidden=true href=#training-the-model>#</a></h2><p>I am going to use a model that already knows how to do something well and train it to make something even better for our needs. This is called transfer learning and it allows us to train models faster.</p><p>The pretrained model I am going to use is called <strong>convnext_tiny_in22k</strong> (previously i tried a <strong>resnet50</strong> variation but i found out that the model I am currently using has a better performance).</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>timm</span><span class=o>.</span><span class=n>create_model</span><span class=p>(</span><span class=s1>&#39;convnext_tiny_in22k&#39;</span><span class=p>,</span> <span class=n>pretrained</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>num_classes</span><span class=o>=</span><span class=n>flores</span><span class=o>.</span><span class=n>c</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>learner_2</span> <span class=o>=</span> <span class=n>Learner</span><span class=p>(</span><span class=n>flores</span><span class=p>,</span> <span class=n>model</span><span class=p>,</span> <span class=n>metrics</span><span class=o>=</span> <span class=n>error_rate</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>learner_2</span><span class=o>.</span><span class=n>fine_tune</span><span class=p>(</span><span class=mi>4</span><span class=p>)</span>
</span></span></code></pre></div><h2 id=saving-the-model>Saving the model<a hidden class=anchor aria-hidden=true href=#saving-the-model>#</a></h2><p>The next line will download the model as a <strong>.pkl</strong> file which can be used to deploy the model.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=line><span class=cl><span class=n>learner_2</span><span class=o>.</span><span class=n>export</span><span class=p>()</span>
</span></span></code></pre></div><h2 id=model-deployment>Model deployment<a hidden class=anchor aria-hidden=true href=#model-deployment>#</a></h2><p>To deploy the model I am going to use Hugging Face Spaces and Gradio using the following script. It will require to upload the <strong>.pkl</strong> file and an optional example file.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=line><span class=cl><span class=kn>from</span> <span class=nn>fastai.vision.all</span> <span class=kn>import</span> <span class=o>*</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>gradio</span> <span class=k>as</span> <span class=nn>gr</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>timm</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>learner</span> <span class=o>=</span> <span class=n>load_learner</span><span class=p>(</span><span class=s2>&#34;./export.pkl&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>categorias</span> <span class=o>=</span> <span class=n>learner</span><span class=o>.</span><span class=n>dls</span><span class=o>.</span><span class=n>vocab</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>clasificar_imagen</span><span class=p>(</span><span class=n>img</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>prediccion</span><span class=p>,</span> <span class=n>indice</span><span class=p>,</span> <span class=n>probabilidades</span> <span class=o>=</span> <span class=n>learner</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>img</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=nb>dict</span><span class=p>(</span><span class=nb>zip</span><span class=p>(</span><span class=n>categorias</span><span class=p>,</span><span class=nb>map</span><span class=p>(</span><span class=nb>float</span><span class=p>,</span><span class=n>probabilidades</span><span class=p>)))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>imagen</span> <span class=o>=</span> <span class=n>gr</span><span class=o>.</span><span class=n>inputs</span><span class=o>.</span><span class=n>Image</span><span class=p>(</span><span class=n>shape</span><span class=o>=</span><span class=p>(</span><span class=mi>500</span><span class=p>,</span><span class=mi>500</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>etiqueta</span> <span class=o>=</span> <span class=n>gr</span><span class=o>.</span><span class=n>outputs</span><span class=o>.</span><span class=n>Label</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>ejemplo</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;girasol.jpg&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>interfaz</span> <span class=o>=</span> <span class=n>gr</span><span class=o>.</span><span class=n>Interface</span><span class=p>(</span><span class=n>fn</span><span class=o>=</span><span class=n>clasificar_imagen</span><span class=p>,</span><span class=n>inputs</span><span class=o>=</span><span class=n>imagen</span><span class=p>,</span><span class=n>outputs</span><span class=o>=</span><span class=n>etiqueta</span><span class=p>,</span> <span class=n>examples</span><span class=o>=</span><span class=n>ejemplo</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>interfaz</span><span class=o>.</span><span class=n>launch</span><span class=p>(</span><span class=n>inline</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span></code></pre></div><h2 id=try-it-out>Try it out<a hidden class=anchor aria-hidden=true href=#try-it-out>#</a></h2><p>Check the result and let me know how it goes! <strong>:)</strong>
<iframe src=https://mateocontreras-fastai-flower-classif.hf.space frameborder=0 width=850 height=450></iframe></p></div><footer class=post-footer><ul class=post-tags><li><a href=/tags/python/>Python</a></li><li><a href=/tags/image-processing/>Image Processing</a></li><li><a href=/tags/flowers/>Flowers</a></li></ul></footer><div class=giscus_comments><script src=https://giscus.app/client.js data-repo=jesse-wei/jessewei.dev-PaperMod data-repo-id=R_kgDOJhJgPg data-category=Comments data-category-id=DIC_kwDOJhJgPs4CWei3 data-mapping=pathname data-strict=1 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=top data-theme=preferred_color_scheme data-lang=en data-loading=lazy crossorigin=anonymous async></script></div><script async>document.querySelector("div.giscus_comments > script").setAttribute("data-theme",localStorage.getItem("pref-theme")?localStorage.getItem("pref-theme"):window.matchMedia("(prefers-color-scheme: dark)").matches?"transparent_dark":"light"),document.querySelector("#theme-toggle").addEventListener("click",()=>{let e=document.querySelector("iframe.giscus-frame");e&&e.contentWindow.postMessage({giscus:{setConfig:{theme:localStorage.getItem("pref-theme")?localStorage.getItem("pref-theme")==="dark"?"light":"transparent_dark":document.body.className.includes("dark")?"light":"transparent_dark"}}},"https://giscus.app")})</script></article></main><footer class=footer style=padding-top:18px;padding-bottom:18px><div class=social-icons style=padding-bottom:0><a style=border-bottom:none href=https://github.com/mateocontrerass rel=me title=Github><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a><a style=border-bottom:none href=https://www.linkedin.com/in/mateocontreras/ rel=me title=Linkedin data-proofer-ignore><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M16 8a6 6 0 016 6v7h-4v-7a2 2 0 00-2-2 2 2 0 00-2 2v7h-4v-7a6 6 0 016-6z"/><rect x="2" y="9" width="4" height="12"/><circle cx="4" cy="4" r="2"/></svg></a><a style=border-bottom:none href=mailto:mateocontrerassilva@outlook.com rel=me title=Email><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 21" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 4h16c1.1.0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1.0-2-.9-2-2V6c0-1.1.9-2 2-2z"/><polyline points="22,6 12,13 2,6"/></svg></a></div><span>&copy; 2023 <a href>Mateo Contreras</a></span>
<span>•
Powered by
<a href=https://gohugo.io/>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/>PaperMod</a></span>
<span>•
<a href=/privacy>Privacy Policy</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let b=document.querySelector("#menu-trigger"),m=document.querySelector(".menu");b.addEventListener("click",function(){m.classList.toggle("hidden")}),document.body.addEventListener("click",function(e){b.contains(e.target)||m.classList.add("hidden")})</script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>